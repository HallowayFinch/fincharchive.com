name: github-pages

on:
  push:
    branches: [ "main" ]
    # Rebuild when site-relevant files change (now includes JSON/TXT, CNAME)
    paths:
      - "_config.yml"
      - "_data/**"
      - "_includes/**"
      - "_layouts/**"
      - "_logs/**"
      - "_field-notes/**"
      - "_posts/**"
      - "artifacts/**"
      - "assets/**"
      - "**/*.html"
      - "**/*.md"
      - "**/*.css"
      - "**/*.js"
      - "**/*.json"        # feed.json, site.webmanifest, etc.
      - "**/*.txt"         # robots.txt, humans.txt, etc.
      - "feed.json"
      - "robots.txt"
      - "site.webmanifest"
      - "CNAME"
  workflow_dispatch: {}
  # Also rebuild when the ingest workflows complete (so GITHUB_TOKEN pushes publish)
  workflow_run:
    workflows:
      - "RSS → Repo (Substack sync)"
      - "Import Field Notes from Substack"
    types: [completed]

permissions:
  contents: read
  pages: write
  id-token: write

concurrency:
  group: "pages"
  cancel-in-progress: true

jobs:
  build:
    runs-on: ubuntu-latest

    outputs:
      site_changed: ${{ steps.compute.outputs.site }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          # Ensure we have commit history for diffing on workflow_run
          fetch-depth: 0

      # --- PATH FILTERS -------------------------------------------------------
      # On push: normal paths-filter against the pushed changes
      - name: Filter for site changes (push)
        id: filter_push
        if: github.event_name == 'push'
        uses: dorny/paths-filter@v3
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          filters: |
            site:
              - '_config.yml'
              - '_data/**'
              - '_includes/**'
              - '_layouts/**'
              - '_logs/**'
              - '_field-notes/**'
              - '_posts/**'
              - 'artifacts/**'
              - 'assets/**'
              - '**/*.html'
              - '**/*.md'
              - '**/*.css'
              - '**/*.js'
              - '**/*.json'
              - '**/*.txt'
              - 'feed.json'
              - 'robots.txt'
              - 'site.webmanifest'
              - 'CNAME'

      # On workflow_run: compare ONLY the upstream run's head commit vs its parent.
      # If the importer made no commit (no changes), this diff will be empty, so we skip.
      - name: Determine diff refs (workflow_run)
        id: refs
        if: github.event_name == 'workflow_run'
        run: |
          SHA="${{ github.event.workflow_run.head_sha }}"
          echo "head_sha=$SHA" >> "$GITHUB_OUTPUT"
          # Parent of head (may be merge commit; first parent is fine here)
          PARENT="$(git rev-parse "${SHA}^")"
          echo "base_sha=$PARENT" >> "$GITHUB_OUTPUT"
          echo "Upstream head: $SHA"
          echo "Upstream base: $PARENT"

      - name: Filter for site changes (workflow_run)
        id: filter_wr
        if: github.event_name == 'workflow_run' && github.event.workflow_run.conclusion == 'success'
        uses: dorny/paths-filter@v3
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          base: ${{ steps.refs.outputs.base_sha }}
          ref:  ${{ steps.refs.outputs.head_sha }}
          filters: |
            site:
              - '_config.yml'
              - '_data/**'
              - '_includes/**'
              - '_layouts/**'
              - '_logs/**'
              - '_field-notes/**'
              - '_posts/**'
              - 'artifacts/**'
              - 'assets/**'
              - '**/*.html'
              - '**/*.md'
              - '**/*.css'
              - '**/*.js'
              - '**/*.json'
              - '**/*.txt'
              - 'feed.json'
              - 'robots.txt'
              - 'site.webmanifest'
              - 'CNAME'

      # --- BUILD GATE ---------------------------------------------------------
      - name: Decide build gate
        id: compute
        run: |
          if [ "${{ github.event_name }}" = "workflow_run" ]; then
            if [ "${{ github.event.workflow_run.conclusion }}" != "success" ]; then
              echo "site=false" >> "$GITHUB_OUTPUT"
              exit 0
            fi
            if [ "${{ steps.filter_wr.outputs.site }}" = "true" ]; then
              echo "site=true" >> "$GITHUB_OUTPUT"
            else
              echo "No site-relevant changes in upstream run; skipping."
              echo "site=false" >> "$GITHUB_OUTPUT"
            fi
          else
            if [ "${{ steps.filter_push.outputs.site }}" = "true" ]; then
              echo "site=true" >> "$GITHUB_OUTPUT"
            else
              echo "No site-relevant changes in push; skipping."
              echo "site=false" >> "$GITHUB_OUTPUT"
            fi
          fi

      # --- VALIDATE & BUILD ---------------------------------------------------
      - name: Validate front matter
        if: steps.compute.outputs.site == 'true'
        run: |
          python3 -m pip install --quiet PyYAML
          python3 - << 'PY'
          import os, re, sys, yaml
          REQUIRED = {"title", "date"}
          ok = True
          for folder in ["_logs", "_field-notes", "_posts"]:
              if not os.path.isdir(folder):
                  continue
              for fn in os.listdir(folder):
                  if not fn.endswith((".md", ".markdown")):
                      continue
                  path = os.path.join(folder, fn)
                  with open(path, "r", encoding="utf-8") as f:
                      text = f.read()
                  m = re.match(r"^---\n(.*?)\n---", text, re.S)
                  if not m:
                      print(f"[x] Missing front matter: {path}")
                      ok = False
                      continue
                  try:
                      data = yaml.safe_load(m.group(1)) or {}
                  except Exception as e:
                      print(f"[x] YAML error in {path}: {e}")
                      ok = False
                      continue
                  missing = REQUIRED - set(data.keys())
                  if missing:
                      print(f"[x] {path} missing: {', '.join(sorted(missing))}")
                      ok = False
          sys.exit(0 if ok else 1)
          PY

      - name: Setup Python (for pagination generator)
        if: steps.compute.outputs.site == 'true'
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Generate paginated log pages (no commit)
        if: steps.compute.outputs.site == 'true'
        env:
          LOGS_PER_PAGE: "12"
        run: |
          python - << 'PY'
          import os, math, pathlib, shutil
          ROOT = pathlib.Path('.').resolve()
          LOG_DIR = ROOT / "_logs"
          PAGES_ROOT = ROOT / "logs" / "page"
          PER_PAGE = int(os.environ.get("LOGS_PER_PAGE", "12"))
          def count_logs():
              if not LOG_DIR.exists():
                  return 0
              return sum(1 for p in LOG_DIR.iterdir() if p.is_file() and p.suffix.lower() in {".md", ".markdown"})
          def write_page(n: int):
              d = PAGES_ROOT / str(n)
              d.mkdir(parents=True, exist_ok=True)
              out = d / "index.md"
              fm = f"""---
          layout: logs
          title: Logs · Page {n}
          permalink: /logs/page/{n}/
          page_num: {n}
          per_page: {PER_PAGE}
          ---
          """
              out.write_text(fm, encoding="utf-8")
          def cleanup_extra(from_n_plus_one: int):
              if not PAGES_ROOT.exists():
                  return
              for child in PAGES_ROOT.iterdir():
                  if child.is_dir():
                      try:
                          pn = int(child.name)
                      except ValueError:
                          continue
                      if pn >= from_n_plus_one:
                          shutil.rmtree(child, ignore_errors=True)
          total_logs = count_logs()
          total_pages = math.ceil(total_logs / PER_PAGE) if total_logs else 1
          for n in range(2, total_pages + 1):
              write_page(n)
          cleanup_extra(total_pages + 1)
          print(f"[gen_log_pages] logs={total_logs}, per_page={PER_PAGE}, pages={total_pages}")
          PY

      - name: Setup Pages
        if: steps.compute.outputs.site == 'true'
        uses: actions/configure-pages@v5

      - name: Build with Jekyll
        if: steps.compute.outputs.site == 'true'
        uses: actions/jekyll-build-pages@v1
        with:
          source: ./
          destination: ./_site
        env:
          JEKYLL_ENV: production

      - name: Upload artifact
        if: steps.compute.outputs.site == 'true'
        uses: actions/upload-pages-artifact@v3
        with:
          path: ./_site

  deploy:
    needs: build
    runs-on: ubuntu-latest
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    if: needs.build.outputs.site_changed == 'true'
    steps:
      - id: deployment
        uses: actions/deploy-pages@v4
